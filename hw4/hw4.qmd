---
title: "Biostat 200C Homework 4"
subtitle: Due May 23  @ 11:59PM
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

```{r}
library(faraway) 
library(MASS) 
library(ggplot2)
library(tidyverse)
library(mice) 
library(MASS) 
```

## Q1. ELMR Excercise 7.5 (p150) 

The debt data arise from a large postal survey on the psychology of debt. The frequency of credit card use is a three-level factor ranging from never, through occasionally to regularly.

```{r}
data(debt)
View(debt) 
```

(a) Declare the response as an ordered factor and make a plot showing the relationship to prodebt. Comment on the plot. Use a table or plot to display the relationship between the response and the income group.

**Solution ** 

1. Plot showcasing the relationship between credit card usage and pro-debt attitudes: 
The boxplot below illustrates how pro-debt attitudes (measured on a scale where higher values indicate a more favorable view of debt) vary according to credit card use frequency: never, occasionally, and regularly. There is a positive trend between the frequency of credit card use and pro-debt attitudes. Specifically, individuals who have never used credit cards tend to have lower pro-debt scores, with a median around 3. Those who occasionally use credit cards show a slight increase in the median pro-debt attitude, suggesting a more accepting view of debt. Finally, individuals who are regular credit card users have the highest median pro-debt score, indicating a stronger acceptance of debt. The spread of values is fairly consistent across groups, though outliers are more evident among those who use credit cards less frequently. Overall, the plot suggests that more frequent credit card users tend to have a more pro-debt mindset.

```{r}
debt$ccarduse <- factor(debt$ccarduse, 
                            levels = c(1, 2, 3), 
                            labels = c("never", "occasionally", "regularly"), 
                            ordered = TRUE)
```

```{r}
filtered_data <- debt %>%
  filter(!is.na(ccarduse), !is.na(prodebt))

ggplot(filtered_data, aes(x = ccarduse, y = prodebt, fill = ccarduse)) +
  geom_boxplot(alpha = 0.7, color = "black") +
  scale_fill_brewer(palette = "Pastel1") +  
  labs(
    title = "Pro-Debt Attitude by Credit Card Use Frequency",
    subtitle = "Survey analysis on credit behavior and debt attitude",
    x = "Credit Card Use Frequency",
    y = "Pro-Debt Attitude Score",
    fill = "Credit Card Use"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 12, margin = margin(b = 10)),
    legend.position = "none" 
  )
```


2. Plot showcasing Credit Card Use Frequency by Income Group: 
Shown below is a stacked proportional bar plot and the corresponding frequency table, showcasing the values corresponding to various levels of income group and credit card usage frequency. In lower income groups (1 and 2), the vast majority of individuals never used credit cards, with proportions exceeding 75 percent. As the income group increases, there is a gradual decline in the proportion of non-users and a rise in regular credit card usage. In the highest income group (indicated by 5), nearly half of individuals use credit cards regularly, while the proportion of individuals who have never used a credit card drops significantly. Occasional usage of credit cards (represented by the cyan color) remains stable across groups but also increases slightly with income. All in all, the stacked proportional bar plot suggests that higher income is positively associated with more frequent credit card use.

```{r}
filtered_data <- subset(debt, !is.na(ccarduse) & !is.na(incomegp))
table(filtered_data$ccarduse, filtered_data$incomegp)
ggplot(filtered_data, aes(x = incomegp, fill = ccarduse)) +
  geom_bar(position = "fill") +
  labs(title = "Credit Card Use Frequency by Income Group",
       x = "Income Group",
       y = "Proportion",
       fill = "Credit Card Use") +
  theme_minimal()
```

(b) Fit a proportional odds model for credit card use with all the other variables as predictors. What are the two most significant predictors (largest t-values) and what is their qualitative effect on the response? What is the least significant predictor?

**Solution ** 
The two most significant predictors (based on the largest t-values) are incomegp (t-value of 4.44) and bankacc (t-value of 3.55).

Interpretation for incomegp: Income group is a highly significant predictor of credit card use frequency. The odds of moving from "never" to "occasionally," or from "never/occasionally" to "regularly" using a credit card increase by a factor of exp(0.47) ≈ 1.6 for each additional increase in income group level.

Interpretation for bankacc: Having a bank account is another strong predictor of credit card use frequency. The odds of moving from "never" to "occasionally," or from "never/occasionally" to "regularly" using a credit card increase by a factor of exp(2.102) ≈ 8.18 for individuals who have a bank account compared to those who do not.

The least significant predictor is house (t-value of 0.499225). Whether or not an individual owns a house does not meaningfully differentiate their likelihood of using a credit card. If we were to interpret the coefficient for this predictor, it would suggest that the odds of moving from "never" to "occasionally," or from "occasionally" to "regularly" using a credit card increase by a factor of approximately 1.122 (exp(0.116) for individuals who own a house compared to those who do not. However, given the low t-value, this effect is not statistically significant.

```{r}
model <- polr(ccarduse ~ ., data = debt, Hess = TRUE, na.action = na.omit)
coef_summary <- coef(summary(model))

predictor_summary <- coef_summary[!grepl("/", rownames(coef_summary)), ]
t_values <- predictor_summary[, "t value"]
p_values <- pnorm(abs(t_values), lower.tail = FALSE) * 2

results <- data.frame(
  Predictor = rownames(predictor_summary),
  Coefficient = predictor_summary[, "Value"],
  Std_Error = predictor_summary[, "Std. Error"],
  t_value = t_values,
  p_value = p_values
) |> 
  arrange(desc(abs(t_value)))
results
```

(c) Fit a proportional odds model using only the least significant predictor from the previous model. What is the significance of this predictor in this small model? Are the conclusions regarding this predictor contradictory for the two models?

**Solution ** 

Below, we fit a proportional odds model using only the least significant predictor (house) from the previous model. In the full model, the house predictor is not statistically significant (p-value = 0.6176), suggesting no meaningful contribution to the frequency of credit card usage when other predictors are included. In the reduced model, however, house becomes highly significant (p-value = 0.0001), with a much larger coefficient of 0.558 and a t-value of 3.8951. This implies that when house is considered in isolation, it appears to have a strong relationship with credit card use frequency.

Interpretation of the coefficient: The odds of moving from "never" to "occasionally," or from "never/occasionally" to "regularly" using a credit card increase by a factor of exp(0.558) ≈ 1.747 for individuals who own a house compared to those who do not.

```{r}
full_model <- polr(ccarduse ~ ., data = debt, Hess = TRUE, na.action = na.omit)
reduced_model <- polr(ccarduse ~ house, data = debt, Hess = TRUE, na.action = na.omit)

extract_house_stats <- function(model) {
  sumry <- coef(summary(model))
  house_row <- sumry[rownames(sumry) == "house", ]
  t_val <- house_row["t value"]
  p_val <- pnorm(abs(t_val), lower.tail = FALSE) * 2
  data.frame(
    Coefficient = house_row["Value"],
    Std_Error = house_row["Std. Error"],
    t_value = t_val,
    p_value = p_val
  )
}

comparison_table <- rbind(
  data.frame(Model = "Full Model", extract_house_stats(full_model)),
  data.frame(Model = "Reduced Model", extract_house_stats(reduced_model))
)

knitr::kable(comparison_table, digits = 4, 
             caption = "Comparison of 'house' Predictor in Full vs. Reduced Models")
```


(d) Use stepwise AIC to select a smaller model than the full set of predictors. You will need to handle the missing values carefully. Report on the qualitative effect of the predictors in your chosen model. Can we conclude that the predictors that were dropped from the model have no relation to the response?

**Solution ** 




(e) Compute the median values of the predictors in your selected model. At these median values, contrast the predicted outcome probabilities for both smokers and nonsmokers.

**Solution ** 
We compute the median values of the predictors in the selected model from the previous question. 
The 

```{r}

```


(f) Fit a proportional hazards model to the same set of predictors and recompute the two sets of probabilities from the previous question. Does it make a difference to use this type of model?

**Solution ** 

```{r}

```


## Q2. Moments of exponential family distributions

**Solution** 
Solution is on another page. 

## Q3. Score and information matrix of GLM

**Solution ** 
Solution is on another page. 

## Q4. ELMR Exercise 8.1 (p171)

**Solution ** 
Solution is on another page. 

## Q5. ELMR Exercise 8.4 (p172)

Consider the Galápagos data and model analyzed in this chapter. The purpose of this question is to reproduce the details of the GLM fitting of this data.

```{r}
data(gala)
View(gala) 
```


(a) Fit a Poisson model to the species response with the five geographic variables as predictors. Do not use the endemics variable. Report the values of the coefficients and the deviance.

**Solution ** 

After fitting a Poisson model to the species response with the five geographic variables as predictors, we obtain the coefficients as follows: Intercept: 3.1548078779, Area: -0.0005799429, Elevation: 0.0035405940, Nearest: 0.0088255719, Scruz: -0.0057094223, and Adjacent: -0.0006630311. The deviance is reported as 716.8458. 

```{r}
model_poisson <- glm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent,
                     family = poisson(link = "log"),
                     data = gala)
```

```{r}
coef(model_poisson)
deviance_poisson <- deviance(model_poisson)
deviance_poisson
```

(b) For a Poisson GLM, derive η, dη/dµ, V (µ) and the weights to be used in an iteratively fit GLM. What is the form of the adjusted dependent variable here?

**Solution ** 
Solution is on another page. 

(c) Using the observed response as initial values, compute the first stage of the iteration, stopping after the first linear model fit. Compare the coefficients of this linear model to those found in the GLM fit. How close are they?

**Solution ** 

We perform a comparison between the first iteration of the Iteratively Reweighted Least Squares algorithm (manually computed counts as initial estimates) and the final fit of a Poisson Generalized Linear Model (converged solution from glm()). The code first manually calculates the adjusted dependent variable (z) and weights usng the initial assumption that the Poisson mean (u) equals the observed count (y). A weighted linear model is then fitted using these values, yielding the First_Iteration coefficient estimates. In addition, a Poisson GLM is fitted using the glm() function to produce the Final_GLM coefficients (the same model that we fit initially). The resulting table compares both sets of coefficients for each predictor and shows the difference and relative difference between the two sets of values. We are able to see that the while most of the coefficients from the first iteration are fairly close to the final GLM values, some (like Nearest and Scruz) have more notable differences, particularly in relative terms. The relative difference between the two sets of coefficients of the Nearest coefficient is -0.7146 or -71.5 percent (first iteration underestimates the final coefficient). The relative difference between the two sets of coefficient of the Scruz coefficient is -0.3362 or -33.6 percent (first iteration underestimates the final coefficient). The relative difference of +11.6 percent (first iteration overestimates). These differences may have occurred because the first iteration uses naive initial values (u = y) which can be unstable (especially for y = 0). The log link introduces nonlinearity, requiring multiple iterations to refine estimates. Predictors such as Nearest and Scruz may have nonlinear relationships with the response, which the first iteraction cannot capture. This indicates that the first iteraction provides a rough approximation but should not be used as the final model. Subsequent iterations adjust weights and working responses to converge to the maximum likelihood estimates. 

```{r}
y <- gala$Species  
X <- model.matrix(~ Area + Elevation + Nearest + Scruz + Adjacent, data = gala) 

mu_init <- ifelse(y == 0, 0.1, y)
eta_init <- log(mu_init)
z_init <- eta_init + (y - mu_init)/mu_init
weights_init <- mu_init
first_iter_model <- lm(z_init ~ X - 1, weights = weights_init)
beta_first_iter <- coef(first_iter_model)

final_glm <- glm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent,
                family = poisson(link = "log"),
                data = gala)
beta_final <- coef(final_glm)

results <- data.frame(
  Predictor = colnames(X),
  First_Iteration = round(beta_first_iter, 6),
  Final_GLM = round(beta_final, 6),
  Difference = round(beta_first_iter - beta_final, 6),
  Relative_Difference = round((beta_first_iter - beta_final)/beta_final, 4)
)

print(results)
```


(d) Continue the iteration to get the next η and µ. Use this to compute the current value of the deviance. How close is this to the deviance from the GLM?

**Solution ** 
The second iteration updates the linear predictor, fitted means, and weights, then fits another weighted linear model (lm_iter2) to refine the coefficients (beta_iter2). The deviance after the second iteration is calculated as 828.01, which remains significantly higher than the final GLM deviance (716.85), indicating that the model has not yet fully converged. The coefficients from the second iteration (e.g., Nearest: 0.00772 and Scruz: -0.00524) are closer to the final GLM estimates (Nearest: 0.00883, Scruz: -0.00571) than those from the first iteration, demonstrating the algorithm's progress. However, the remaining difference in deviance (111.16) suggests that additional iterations are required for convergence.

```{r}
final_glm <- glm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent,
                 family = poisson, data = gala)
final_deviance <- deviance(final_glm)  

y <- gala$Species
X <- model.matrix(~ Area + Elevation + Nearest + Scruz + Adjacent, data = gala)
mu <- ifelse(y == 0, 0.1, y) 
eta <- log(mu)
z <- eta + (y - mu) / mu
weights <- mu
lm_iter1 <- lm(z ~ X - 1, weights = weights)
beta_iter1 <- coef(lm_iter1)

eta <- X %*% beta_iter1         
mu <- exp(eta)                 
z <- eta + (y - mu) / mu       
weights <- mu                  


lm_iter2 <- lm(z ~ X - 1, weights = weights)
beta_iter2 <- coef(lm_iter2)
deviance_iter2 <- 2 * sum(ifelse(y == 0, mu, y * log(y / mu) - (y - mu)))

cat("Deviance after 2nd iteration:", deviance_iter2, "\n")
cat("Final GLM deviance:", final_deviance, "\n")
cat("Difference:", deviance_iter2 - final_deviance, "\n")

results <- data.frame(
  Predictor = colnames(X),
  Iter1 = round(beta_iter1, 5),
  Iter2 = round(beta_iter2, 5),
  Final_GLM = round(coef(final_glm), 5))
print(results)
```

(e) Compute one more iteration of the GLM fit, reporting the next calculation of the coefficients and deviance. How close are these to target now?

**Solution ** 

The third iteration updates the linear predictor, fitted means, and weights, then fits another weighted linear model (lm_iter3) to refine the coefficients (beta_iter3). The deviance after the third iteration is calculated as 719.4158, which is significantly closer to the final GLM deviance (716.85), indicating substantial progress toward convergence in the IRLS algorithm for the Poisson GLM. The third-iteration coefficients (Iter3) are now extremely close to the final GLM estimates, with near-identical values for most predictors. For instance: The Nearest coefficient improved from 0.00252 (Iter1) to 0.00879 (Iter3), nearly matching the final value of 0.00883. The intercept converged from 3.51915 to 3.15626 (vs. the final 3.15481). The deviance also decreased sharply from 828.01 (Iteration 2) to 719.42 (Iteration 3), leaving a negligible difference of 2.57 compared to the final deviance (716.85). This minimal gap demonstrates that the third iteration captures almost all underlying relationships, placing the model on the brink of full convergence.

```{r}
eta <- X %*% beta_iter2           
mu <- exp(eta)                    
z <- eta + (y - mu) / mu         
weights <- mu                     

lm_iter3 <- lm(z ~ X - 1, weights = weights)
beta_iter3 <- coef(lm_iter3)

deviance_iter3 <- 2 * sum(ifelse(y == 0, mu, y * log(y / mu) - (y - mu)))
                          
results <- data.frame(
  Predictor = colnames(X),
  Iter1 = round(beta_iter1, 5),
  Iter2 = round(beta_iter2, 5),
  Iter3 = round(beta_iter3, 5),
  Final_GLM = round(coef(final_glm), 5)
)

print(results)
cat("\nDeviance after 3rd iteration:", deviance_iter3, "\n")
cat("Final GLM deviance:", final_deviance, "\n")
cat("Difference:", deviance_iter3 - final_deviance, "\n")
```

(f) Repeat these iterations a few more times, computing the deviance in each time. Stop when the deviance does not change much. Compare your final estimated coefficients to that produced by the GLM fit.

**Solution ** 
After running several iterations, we observe that the deviance stabilizes at 716.8458 after just 5 iterations, with only negligible changes in the coefficients. The exact match between the IRLS deviance (716.8458) and the GLM deviance (difference: 2.27e-13) confirms that our IRLS implementation is both mathematically correct and numerically stable. The IRLS and GLM coefficient estimates are identical across all predictors (all differences = 0). For instance, the Nearest coefficient (0.008826) is precisely the same in both methods. The intercept (3.154808) also matches exactly. This agreement validates that our manual IRLS implementation perfectly replicates the results of glm(). The iterative approach successfully approximates the GLM fit by progressively refining the weights and working responses, demonstrating the underlying mechanics of generalized linear modeling.

```{r}
y <- gala$Species
X <- model.matrix(~ Area + Elevation + Nearest + Scruz + Adjacent, data = gala)
mu <- ifelse(y == 0, 0.1, y)
eta <- log(mu)
deviance_history <- numeric(100)
coef_history <- matrix(nrow = 100, ncol = ncol(X))

for (iter in 1:100) {
  z <- eta + (y - mu) / mu
  weights <- mu

  current_lm <- lm(z ~ X - 1, weights = weights)
  current_coef <- coef(current_lm)
  
  coef_history[iter, ] <- current_coef

  eta <- X %*% current_coef
  mu <- exp(eta)
  mu <- pmax(mu, 1e-10)
  
  current_deviance <- 2 * sum(ifelse(y == 0, mu, y * log(y / mu) - (y - mu)))
  deviance_history[iter] <- current_deviance
  if (iter > 1 && abs(deviance_history[iter] - deviance_history[iter - 1]) < 1e-4) {
    break
  }
}
n_iter <- iter
final_iter_coef <- coef_history[n_iter, ]
final_glm <- glm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent,
                 family = poisson(link = "log"), data = gala)
final_glm_coef <- coef(final_glm)
final_glm_deviance <- deviance(final_glm)

results <- data.frame(
  Predictor = colnames(X),
  IRLS_Estimate = round(final_iter_coef, 6),
  GLM_Estimate = round(final_glm_coef, 6),
  Difference = round(final_iter_coef - final_glm_coef, 6)
)
cat("Converged after", n_iter, "iterations.\n")
cat("Final IRLS Deviance:", deviance_history[n_iter], "\n")
cat("GLM Deviance:", final_glm_deviance, "\n")
cat("Deviance Difference:", deviance_history[n_iter] - final_glm_deviance, "\n\n")
print(results)
```

(g) Use your final iterated linear model fit to produce standard errors for the coefficients. How close are these to that produced by the direct GLM fit?

**Solution ** 
To compute the standard errors for the coefficients obtained from the final iteration of the IRLS (Iteratively Reweighted Least Squares) procedure, we used the classic weighted least squares formula for the variance-covariance matrix: 
\[\text{Var}(\hat{\boldsymbol{\beta}}) = \left( \mathbf{X}^\top \mathbf{W} \mathbf{X} \right)^{-1}\], where W is a diagonal matrix of the final fitted values (μ) from the Poisson model. We then extracted the square roots of the diagonal entries of this matrix to obtain the standard errors for each coefficient. These were then compared directly with the standard errors produced by the fully converged glm() function which we obtained from above. 

The results show that the standard errors from our manually iterated IRLS model exactly match those from the glm() function, with a difference of zero for each coefficient. For instance, the standard error for the Nearest predictor from both models is 0.001821 and the standard error for the Scruz predictor from both. models is 0.000626. This further confirms that our IRLS implementation correctly converged to the maximum likelihood estimates, both in terms of the coefficients and their uncertainty estimates. It also validates the use of the IRLS method as an equivalent approach to glm() for fitting generalized linear models. 

```{r}
W <- diag(as.vector(mu)) 
XtWX_inv <- solve(t(X) %*% W %*% X)
IRLS_se <- sqrt(diag(XtWX_inv))

GLM_se <- summary(final_glm)$coefficients[, "Std. Error"]

results <- data.frame(
  Predictor = colnames(X),
  IRLS_Estimate = round(final_iter_coef, 6),
  IRLS_SE = round(IRLS_se, 6),
  GLM_Estimate = round(final_glm_coef, 6),
  GLM_SE = round(GLM_se, 6),
  SE_Difference = round(IRLS_se - GLM_se, 6)
)
print(results)
```

## Q6. ELMR Exercise 8.5 (p172)

Again using the Galápagos data, fit a Poisson model to the species response with the five geographic variables as predictors. Do not use the endemics variable. The purpose of this question is to compare six different ways of testing the significance of the elevation predictor, i.e., H0 : βElev = 0. In each case, report the p-value.

(a) Use the z-statistic from the model summary.

```{r}
model <- glm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent, 
             family = poisson, 
             data = gala)

model_summary <- summary(model)
elevation_z <- model_summary$coefficients["Elevation", "z value"]
elevation_p <- model_summary$coefficients["Elevation", "Pr(>|z|)"]

cat("(a) Z-statistic test for Elevation:\n")
cat("Z-value:", elevation_z, "\n")
cat("p-value:", elevation_p, "\n")
```


(b) Fit a model without elevation and use the difference in deviances to make the test.

```{r}
model_no_elevation <- glm(Species ~ Area + Nearest + Scruz + Adjacent, 
             family = poisson, 
             data = gala)

model_summary <- summary(model_no_elevation)
```


(c) Use the Pearson Chi-squared statistic in place of the deviance in the previous test.

```{r}

```


(d) Fit the Poisson model with a free dispersion parameter as described in Section 5.2. Make the test using the model summary.

```{r}

```


(e) Use the sandwich estimation method for the standard errors in the original model. Use these to compute z-statistics.

```{r}

```

(f) Use the robust GLM estimation method and report the test result from the summary.

```{r}

```

(g) Compare all six results. Pick the best one and justify your choice.


```{r}

```









