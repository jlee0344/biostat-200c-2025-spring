---
title: "Biostat 200C Homework 1"
subtitle: Due Apr 11 @ 11:59PM
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

```{r}
library(gtsummary)
library(GGally)
library(knitr)
library(tidyverse)
library(faraway)
library(gridExtra)
library(splines)
library(mlbench)
library(lmtest)
library(mice)
library(MASS)
library(ggplot2)
library(tidyr)
library(dplyr) 
library(corrplot)
library(ggplot2)

```


To submit homework, please submit Rmd and html files to bruinlearn by the deadline.

## Q1. Reivew of linear models (60pts)

The swiss data — use Fertility as the response to practice

### Q1.1

An initial data analysis that explores the numerical and graphical characteristics of the data.(5pts)

**Solution ** 
According to online sources, the Swiss Fertility and Socioeconomic Indicators dataset represent the standardized fertility measure and socioeconomic indicators for each of the 47 French-speaking provinces in Switzerland, dated in 1888. 

The swiss data set is a data frame with 47 observations of 6 variables: Fertility (numeric), Agriculture (numeric), Examination (integer), Education (integer), Catholic (numeric), and Infant Mortality (numeric). The variables are represented as follows: 1. Fertility (commmon fertility measure in Ig), 2. Agriculture (percentage of males involved in agriculture as occupation), 3. Examination (percentages of draftees receiving highest mark on army examination), 4. Education (percentage eduation beyond primary school for draftees), 5. Catholic (percent of catholics as opposed to protestants), 6. Infant Mortality (live births who live less than 1 year). 

```{r}
data(swiss)
```

```{r}
swiss <- swiss %>% 
  as_tibble(rownames = "Provinces") %>%
  print(width = Inf)
```

```{r}
str(swiss)
```
The summary statistics (minimum, 1st quartile, median, mean 3rd quartile, and maximum) of the variables in the swiss dataset are as follows: We are able to obtain the numerical summaries of all these predictor variables becuase they are all quantitiative. 

```{r}
summary(swiss) 
```
Data Visualization Plots: Univariate 

1. Univariate plot of the Fertility Variable (response variable): The distribution appears to be slightly right skewed (positive skewed) where most provinces have moderate fertility rates and a few relatively high nes. There is a single peak, making the distribution approximately unimodal where the most common fertility rates are between 70-75. There are some provinces that have unusually low or high fertility rates (around 35 or 95). 

```{r}
ggplot(swiss, aes(x = Fertility)) +
  geom_histogram(aes(y = ..density..), bins = 20, fill = "skyblue", color = "black", alpha = 0.6) +
  geom_density(color = "darkblue", linewidth = 1) +
  labs(
    title = "Histogram of Fertility Rates in Swiss Provinces",
    x = "Fertility Rate",
    y = "Density"
  ) +
  theme_minimal()
```

2. Boxplots for the Predictor Variables: 

The boxplots show the distribution of the predictor variables (Agriculture, Catholic, Education, Examination, and Infant Mortality) in the swiss dataset. Brief summary of the boxplots: 1. Agriculture: The median percentage of males involved in agriculture as occupation lies between 50-60 percent, the distribution is moderately spread out, and there no clear outliers. 2. Catholic: The distribution for the percent of catholics as opposed to protestants is severely right skewed (positve skewed), the spread is extremely wide, and there are no visible outliers. This indicates that most of the provinces have a small percentage of Catholics. 3. Education: The percentage education beyond primary school for draftees is slightly right skewed (positive skewed), the median is low (between 0 and 10), there are a few notable outliers in the distribution (greater than 30) but the spread of the percentages is narrow. 4. Examination: The distribution for the percentage of draftees receiving highest marks on army examinations is slightly skewed to the right (positively skewed) with no strong outliers and the median is near the lower end of the IQR. 5. Infant Mortality: The distribution that represents the number of live births who live less than 1 year is fairly symmetrical with a slightly longer upper whisker, the range is narrow, ad the median is around 20. 

```{r}
predictor_vars <- c("Agriculture", "Examination", "Education", "Catholic", "Infant.Mortality")

swiss_long <- swiss %>%
  pivot_longer(cols = all_of(predictor_vars), names_to = "Variable", values_to = "Value")

ggplot(swiss_long, aes(x = "", y = Value)) +
  geom_boxplot(fill = "lightgreen") +
  facet_wrap(~ Variable, scales = "free_y") +
  labs(title = "Boxplots of Predictor Variables", x = "", y = "") +
  theme_minimal()
```
3. Density plots for all variables including Fertility

For better visualization of the distributions of all the predictor variables and the response variable, Fertility, we plot the density plots. The distributions reflect the same characterisitics as the histograms above. 

```{r}
swiss_long <- swiss %>%
  pivot_longer(cols = -Provinces, names_to = "Variable", values_to = "Value")

ggplot(swiss_long, aes(x = Value)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  facet_wrap(~ Variable, scales = "free", ncol = 2) +
  labs(title = "Density Plots of Swiss Dataset Variables")
```

Data Visualization: Multivariable Relationships 

We will create several scatter plots between 2 variables because all 6 variables are continuous. 

```{r}
plot_list <- list()

predictors <- c("Agriculture", "Examination", "Education", "Catholic", "Infant.Mortality")
for(predictor in predictors) {
  p <- ggplot(swiss, aes_string(x = predictor, y = "Fertility")) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE) +
    ggtitle(paste("Fertility vs", predictor)) +
    theme_minimal()
  
  plot_list[[predictor]] <- p
}

grid.arrange(grobs = plot_list, ncol = 2) 
```

Data Visualization: Correlation Plots

```{r}
# Calculate correlations (remove non-numeric 'Provinces' column)
cor_matrix <- cor(swiss[, -1])  # -1 excludes first column

# Basic correlation plot
corrplot(cor_matrix, method = "circle")

# Enhanced version with values and ordering
corrplot(cor_matrix, 
         method = "number",      # Show correlation coefficients
         type = "upper",         # Only show upper triangle
         order = "hclust",       # Cluster variables
         tl.col = "black",       # Text label color
         tl.srt = 45,            # Text label rotation
         addCoef.col = "black")  # Coefficient color
```

### Q1.2

Variable selection to choose the best model. (10pts)

**Solution ** 
We used the stepwise selection method to identify the best linear model for predicting Fertility based on the predictors: Agriculture, Examination, Education, Catholic, and Infant Mortality. The full model included all main effects as well as all possible two-way interactions (e.g., Agriculture:Examination). The step() function was applied to iteratively add and remove terms in order to minimize the Akaike Information Criterion (AIC), using both forward and backward selection.

The resulting best model achieved the lowest AIC score of 317.41 and included the following terms:
Main effects: Agriculture, Examination, Education, Catholic, Infant Mortality
Interaction terms: Agriculture:Examination, Agriculture:Education, Agriculture:Infant.Mortality, Examination:Education, Examination:Infant.Mortality, and Education:Catholic.

All variables in the model were statistically significant except for the interactions Agriculture:Examination and Agriculture:Education. The model has an R-squared value of 0.811, indicating that approximately 81% of the variance in the Fertility variable is explained by the model. Additionally, the overall model is highly significant, with a p-value of 1.283e-09.

```{r}
full_model <- lm(Fertility ~ (Agriculture + Examination + Education + Catholic + Infant.Mortality)^2, data = swiss)
best_model <- step(full_model, direction = "both", trace = FALSE)
summary(best_model)
```

```{r}
cat("AIC of the best model:", AIC(best_model), "\n")
cat("Predictors in the best model:\n")
print(attr(terms(best_model), "term.labels"))
```
The following code performs single-term deletion diagnostics on the best model obtained earlier. It evaluates how the model's performance would change if each term were removed individually. The results show that two interaction terms — Agriculture:Examination and Agriculture:Education — have p-values greater than 0.05, indicating they are not statistically significant.

Additionally, the RSS (Residual Sum of Squares) values associated with these terms are lower compared to the others, meaning that removing these terms results in only a slight increase (or even improvement) in model error. This suggests that these predictors do not contribute meaningfully to improving model fit, and could potentially be removed to simplify the model without significantly compromising performance. 

```{r}
drop1(best_model, test = "F")
```

We will further test to see if the non-signifcant interaction terms can be dropped. Because the p-value is greater than 0.05, we are able to conclude that the two interaction terms: Agriculture:Examination and Agriculture:Education can be dropped. 

```{r}
reduced_model <- update(best_model, . ~ . - Agriculture:Examination - Agriculture:Education)
anova(reduced_model, best_model)  
```
Refitting the final model after dropping the two nonsignificant interaction terms gives us the following: 
$$y=160.178
 −1.217⋅Agriculture
 −3.037⋅Examination
 −0.501⋅Education
 +0.179⋅Catholic
 −3.462⋅Infant.Mortality
 +0.051⋅(Agriculture×Infant.Mortality)
 +0.004⋅(Examination×Education)
 +0.127⋅(Examination×Infant.Mortality)
 −0.012⋅(Education×Catholic) $$

```{r}
final_model <- lm(
  Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality +
              Agriculture:Infant.Mortality + Examination:Education +
              Examination:Infant.Mortality + Education:Catholic,
  data = swiss
)
summary(final_model)
```

### Q1.3

An exploration of transformations to improve the fit of the model. (10pts)

**Solution **

```{r}

transformations <- list(
  log = function(x) log(x + 1),
  inverse = function(x) 1 / (x + 1),
  poly = function(x) poly(x, degree = 2),
  bspline = function(x) bs(x, degree = 3)
)



plot_list <- list()

for (i in 1:nrow(top_models)) {
  pred <- top_models$Predictor[i]
  trans_name <- top_models$Transformation[i]
  trans_fn <- transformations[[trans_name]]
  
  trans_x <- trans_fn(swiss[[pred]])
  
  if (is.matrix(trans_x)) {
    df <- cbind(Fertility = swiss$Fertility, as.data.frame(trans_x))
    model <- lm(Fertility ~ ., data = df)
    pred_vals <- predict(model)
  } else {
    df <- data.frame(Fertility = swiss$Fertility, x = trans_x)
    model <- lm(Fertility ~ x, data = df)
    pred_vals <- predict(model)
  }
  
  plot_df <- data.frame(
    Original = swiss[[pred]],
    Fertility = swiss$Fertility,
    Fitted = pred_vals
  )
  
  p <- ggplot(plot_df, aes(x = Original, y = Fertility)) +
    geom_point(color = "steelblue", alpha = 0.6) +
    geom_line(aes(y = Fitted), color = "darkred") +
    labs(
      title = paste("Fertility vs", pred, "(", trans_name, ")"),
      x = pred,
      y = "Fertility"
    ) +
    theme_minimal()
  
  plot_list[[pred]] <- p
}
print(top_models)
gridExtra::grid.arrange(grobs = plot_list, ncol = 2)

```

### Q1.4

Diagnostics to check the assumptions of your model. (10pts)

```{r}

```

**Solution ** 

We conduct Regression Diagnostics. We recall that the assumptions of the linear model: 
1. Y depends on the covariates in X linearly: E(Y) = XB or E(e) = 0. We use the residual-fitted valu plot, scale location plot, and residual-leverae plto to check for this: 

2. Errors are iid with common variance. We use the QQ plot to check the normality assumption.

```{r}

```


### Q1.5
Some predictions of future observations for interesting values of the predictors.(5pts)

**Solution ** 
```{r}

```


### Q1.6
An interpretation of the meaning of the model by writing a scientific abstract. (<150 words) (10pts)

  + BACKGROUND: brief intro of the study background, what are the existing findings
  
  + OBJECTIVE: state the overall purpose of your research, e.g., what kind of knowledge gap you are trying to fill in
  
  + METHODS: study design (how these data were collected), outcome definitions, statistical procedures used
  
  + RESULTS: summary of major findings to address the question raised in objective
  
  + CONCLUSIONS:


## Q2.(70pts)  

The National Institute of Diabetes and Digestive and Kidney Diseases conducted a study on 768 adult female Pima Indians living near Phoenix. The purpose of the study was to investigate factors related to diabetes. The data may be found in the the dataset `pima`.

```{r}
data(pima)
str(pima)
summary(pima)
```

### Q2.1 

Create a factor version of the test results and use this to produce an interleaved histogram to show how the distribution of insulin differs between those testing positive and negative. Do you notice anything unbelievable about the plot? (5pts)

**Solution **
```{r}
pima$test <- factor(pima$test, levels = c(0,1), labels = c("Negative", "Positive"))
```

Producing an Interleaved Histogram: 

```{r}
ggplot(pima, aes(x = insulin, fill = test)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs( 
    title = "Insulin Levels by Test Result",
    x = "Insulin",
    y = "Count",
    fill = "Test Result"
  ) +
  theme_minimal()
```

Abnormalities of the graph: The histogram displays a large concentration of insulin values at 0, which is highly improbable for human insulin levels. This anomaly likely indicates missing or unrecorded measurements that were incorrectly entered as zero, rather than representing true physiological data. Additionally, the graph reveals the presence of extreme outliers, with some insulin values exceeding 750. Such values are not biologically plausible and may be the result of data entry errors or measurement inaccuracies. 

### Q2.2

Replace the zero values of `insulin` with the missing value code `NA`. Recreate the interleaved histogram plot and comment on the distribution. (5pts)

```{r}
pima$insulin_clean <- ifelse(pima$insulin == 0, NA, pima$insulin)
```

```{r}
ggplot(pima, aes(x = insulin_clean, fill = test)) +
  geom_histogram(position = "identity", bins = 30, alpha = 0.7, na.rm = TRUE) +
  labs(
    title = "Distribution of Insulin Levels by Diabetes Test Result (Excluding Zeros)",
    x = "Insulin",
    y = "Count",
    fill = "Test Result"
  ) +
  theme_minimal() 
```

Creating the interleaved histogram plot: Amongst the Pima Indians who tested negative (pink), the majority of individuals have insulin levels clustered between 0-150. There is a peak at around insulin levels of 100-125. In addition, the distribution of insulin levels is right skewed where there are fewer people with higher insulin levels. There are a couple of outliers of individuals whose insulin levels are above 300. Amongst the Pima Indians who tested positive (blue), the majority of individuals have insulin levels clustered between 100-250. The distribution is more spread out compard to the distribution corresponding to the inuslin levels of the Pima Indians who tested negative. Compared to the negative group, the positive group has a longer right tail, which suggests that some individuals who tested positive have very high insulin levels of above 500. We are able to see that the spike at insulin = 0 that we saw in the previous graph is gone because these 0 values were replaced with NA's which were omitted in the plot. The histogram, therefore, reflects only a fraction of the data which may lead to bias interpretations. 

### Q2.3

Replace the incredible zeroes in other variables with the missing value code. Fit a model with the result of the diabetes test as the response and all the other variables as predictors. How many observations were used in the model fitting? Why is this less than the number of observations in the data frame. (10pts)
 
**Solution ** 
We observe from the output of summary(pima) that several predictor variables have a minimum value of 0, specifically: glucose, diastolic, triceps, insulin, and bmi. These values are medically implausible and likely represent missing data, so we will convert them to N/A. However, we will not convert the 0 values in the pregnant variable, as it is perfectly reasonable for individuals in the dataset to have had zero pregnancies and is therefore not indicative of missing data. 

```{r}
vars_to_clean <- c("glucose", "diastolic", "triceps", "insulin", "bmi")

pima_clean <- pima
pima_clean[vars_to_clean] <- lapply(pima[vars_to_clean], function(x) ifelse(x == 0, NA, x))
```

```{r}
full_model <- glm(test ~ pregnant + glucose + diastolic + triceps + insulin + bmi + diabetes + age,
                 family = binomial,
                 data = pima_clean)

summary(full_model)
```

```{r}
n_used <- nobs(full_model)
n_total <- nrow(pima_clean)

cat("Observations used in model fitting:", n_used, "\n",
    "Total observations in data frame:", n_total, "\n",
    "Observations omitted due to missing values:", n_total - n_used, "\n")
```

The number of observations used in the model fitting is 392. This is fewer than the 768 observations in the original data frame because the glm() function uses only rows with no missing values in any predictor (NA's are excluded). The original dataset included rows with invalid zero values in variables such as glucose, diastolic, triceps, insulin, and bmi, which are not physiologically realistic. These zeroes were replaced with NA, and the rows containing them were excluded during model fitting to ensure data quality. It is important to note that the number of observations that were omitted due to missing values is 376 which makes up a significant portion of the dataset. Using such data may cause bias interpretation, as mentioned below and so it is important to use imputation methods in later interpretations. 

### Q2.4

Refit the model but now without the insulin and triceps predictors. How many observations were used in fitting this model? Devise a test to compare this model with that in the previous question. (10pts)

```{r}
model_reduced <- glm(test ~ pregnant + glucose + diastolic + bmi + diabetes + age,
                     family = binomial(link = "logit"),
                     data = pima_clean)

summary(model_reduced)
```

```{r}
n_used_reduced <- nobs(model_reduced)
cat("Observations used in reduced model that removed insulin and triceps:", n_used_reduced, "\n")
cat("Observations used in Full Model:", n_used, "\n") 
cat("Total observations in data frame:", n_total, "\n")
```

We refit the model without the insulin and triceps predictors to create a reduced model. The number of observations that were used in this reduced model is 724 which is greater than the number of observations that were used in the full model (392 observations). It is possible that the reduced model has more observations than that of the full model because the reduced model did not drop the rows where there were NA values in the insulin and triceps columns. 

```{r}
update_nested <- function(object, formula., ..., evaluate = TRUE) {
    update(object = object, formula. = formula., data = object$model, ..., evaluate = evaluate)
}

full_model <- glm(test ~ pregnant + glucose + diastolic + triceps + insulin + bmi + diabetes + age,
                  family = binomial, data = pima_clean)

reduced_model <- update_nested(full_model, . ~ . - insulin - triceps)

lrt_result <- lrtest(full_model, reduced_model)
print(lrt_result)
```

Test to compare this model to the previous model (that included insulin and triceps): Because the reduced and full models contain a different number of observations, we will use the update_nested function to ensure that the reduced model is fitted on the exact same 392 observations as the full model, which makes the comparison valid. We use the likelihood ratio test to compare the two models. The likelihood ratio test compares the goodness of fit of two models and checks whether removing the two predictors - insulin and triceps significantly worsens the model's fit where the null hypothesis is that the reduced model fits the data just as well as the full model. The p-value is 0.6507 (larger than 0.05) so we fail to reject the null hypothesis. Therefore, we have sufficient evidence to conclude the reduced model (without the 2 predictors insulin and triceps) fits the data just as well as the full model and do not significantly contribute to the model when the other predictors are already included in the model. Therefore, the simpler model (reduced model without the insulin and triceps predictors) is preferred. 

### Q2.5

Use AIC to select a model. You will need to take account of the missing values. Which predictors are selected? How many cases are used in your selected model? (10pts)

**Solution ** 

We perform step-wise selection, adding or dropping predictors to minimize the AIC. We start with the full model that contains all the predictors (pregnant, glucose, diastolic, tricpes, insulin, bmi, diabetes, and age) after removing all the rows that contain NA values. The model selection process of AIC balances the goodness of fit (how well the model explains the data) and the model complexity (penalizes the number of predictors). The lower the AIC, the better the model. Once we start with the full model, we iteratively add or remove predictors (both forward seelctin and backward elimination). 

```{r}
vars_to_clean <- c("glucose", "diastolic", "triceps", "insulin", "bmi")
pima_clean <- pima
pima_clean[vars_to_clean] <- lapply(pima[vars_to_clean], function(x) ifelse(x == 0, NA, x))
```

```{r}
pima_complete <- na.omit(pima_clean)
n_complete <- nrow(pima_complete)
cat("Number of complete cases:", n_complete, "\n")
```

```{r}
full_model <- glm(test ~ pregnant + glucose + diastolic + triceps + insulin + 
                  bmi + diabetes + age,
                  family = binomial,
                  data = pima_complete)

selected_model <- stepAIC(full_model, direction = "both", trace = FALSE)
summary(selected_model)
```

```{r}
cat("\nSelected predictors:", names(coef(selected_model))[-1], "\n")
cat("Number of cases used in selected model:", nobs(selected_model), "\n")
cat("AIC of selected model:", AIC(selected_model), "\n")
```
The model with the lowest AIC value comes out to be the one with the following variables: pregnant + glucose + bmi + diabetes + age. The selected model used 5 predictor variables out of 8. The number of cases used in the selected model is 392 (utilized the dataset that removed all the rows containing the NA values for each predictor variable.) The AIC value of the selected model is 356.8851. The selected model can be characterized as: $$y = -9.992 + 0.084X_1 + 0.036X_2 + 0.078X_3 + 1.151X_4 + 0.034X_5$$

### Q2.6

Create a variable that indicates whether the case contains a missing value. Use this variable as a predictor of the test result. Is missingness associated with the test result? Refit the selected model, but now using as much of the data as reasonable. Explain why it is appropriate to do this. (10pts)

**Solution ** 

First, we create a missingness indicator where 1 means that the row has a missing value (NA) and 0 means that the row does not have any missing values. We indicate this missingness indicator as has_missing. Note that we utilize the pima_clean dataset which is the data after all the 0 values are converted into N/A values. We then use the has_missing variable as a predictor of the test result and we notice that the p-value for the variable is 0.304. This signifies that the cases with missing values are not significantly more likely to test positive for diabetes than complete cases. In other words, we don't have evidence to conclude that the presence of missing data is associated with the test outcome. 

```{r}
pima_clean$has_missing <- ifelse(rowSums(is.na(pima_clean[vars_to_clean])) > 0, 1, 0)

missing_test <- glm(test ~ has_missing, 
                   family = binomial, 
                   data = pima_clean)
summary(missing_test)
```
Next, we will refit the selected model using as much of the data as reasonable. Since missingness isn't significantly associated with the outcome, it is reasonable to assume that the data is missing at random. Therefore, instead of removing rows with missing values (which reduces sample size and power), we can impute the missing values with the mean/median or use other imputation methods such as MICE or keep as many observations as possible where variables required for the model are present. This ensures that more data is retained, increasing the statistical power of the final model. In addition, we are able to avoid any biases introduced by only analyzing complete cases, especialy if missingness isn't strongly related to the "test" response outcome. 

The next chunk of code performs multiple imputation to handle missing data and then analyzes the imputed datasts. We first create 5 imputed datasets to account for the missing values using the (MICE or Multivariate Imputation by Chained Equations) algorithm where the algorithm predicts the missing values based on observed data and variable relationships. We will then refit the previously selected model (logistic regression with the predictors pregnant + glucose + bmi + diabetes + age) on each imputed dataset (5 total datasets). The results from all the of the 5 models are combined into a single pooled estimate. 

```{r}
vars_to_impute <- c("test", "pregnant", "glucose", "bmi", "diabetes", "age", 
                    "diastolic", "triceps", "insulin")
imp <- mice(pima_clean[vars_to_impute], m = 5, method = "pmm", printFlag = FALSE)

models <- with(imp, glm(test ~ pregnant + glucose + bmi + diabetes + age, 
                       family = binomial))
pooled_results <- pool(models)
summary(pooled_results)
```
After refitting the selected model with the imputed datasets, we get the following model: 
$$y = -9.3813 + 0.1230X_1 + 0.0362X_2 + 0.0885X_3 + 0.8760X_4 + 0.0108X_5$$
### Q2.7 

Using the last fitted model of the previous question [model selected in Question 2.5], compute the odds ratio of testing positive for diabetes for a woman with a BMI at the first quartile compared with a woman at the third quartile, assuming that all other factors are held constant? Give a confidence interval for this odds ratio. (10pts)

**Solution ** 

We are utilizing the data set after accounting for the missing values (after removing all NA values). The 

```{r}
bmi_coef <- coef(selected_model)["bmi"]
bmi_se <- summary(selected_model)$coefficients["bmi", "Std. Error"]

bmi_quartiles <- quantile(pima_complete$bmi, probs = c(0.25, 0.75), na.rm = TRUE)
q1 <- bmi_quartiles[1] 
q3 <- bmi_quartiles[2] 
bmi_quartiles
```

```{r}
bmi_diff <- (bmi_coef*(q3 - q1))
or <- exp(bmi_diff) 

ci <- exp(bmi_diff + c(-1.96, 1.96) * bmi_se * (q3 - q1))
sprintf("OR: %.2f (95%% CI: %.2f-%.2f)", or, ci[1], ci[2])
```

The odds ratio of testing positive for diabetes for a woman with a BMI at the first quartile compared with a woman at the third quartile, assuming that all other factors are held constant is 1.973495. In other words, a woman with a BMI at the third quartile (37.1) has 1.9743 times the odds of testing poistive for diabetes compared to a woman with a BMI at the 1st quartile (28.4), assuming that all other predictors (pregnancies, glucose, and age are held constant). The 95 percent confidence interval for the odds ratio is (1.39-2.80). In other words, we are 95 percent confident that the true odds ratio for diabetes risk (comparing Q3 versus Q1 BMI) lies between 1.36 and 2.64 in the population. 


### Q2.8 

Do women who test positive have higher diastolic blood pressures? Is the diastolic blood pressure significant in the regression model? Explain the distinction between the two questions and discuss why the answers are only apparently contradictory. (10pts)

**Solution ** 
In order to check if women who test positive have higher diastolic blood pressures on average, we will compare the mean/median values of the diastolic blood pressures between the two testing groups (those who tested positive versus negative) by using a t-test or the Wilcoxon test. We will first check if the distributions of the Diastolic blood pressures within each group (Negative/Positive Tests) are normally distributed or not. 

```{r}
# Histograms
hist(pima_clean$diastolic[pima_clean$test == "Negative"], main = "Distribution of Diastolic BP (Negative Test)")
hist(pima_clean$diastolic[pima_clean$test == "Positive"], main = "Distribution of Diastolic BP (Positive Test)")

# Q-Q plots
qqnorm(pima_clean$diastolic[pima_clean$test == "Negative"]); qqline(pima_clean$diastolic[pima_clean$test == "Negative"])
qqnorm(pima_clean$diastolic[pima_clean$test == "Positive"]); qqline(pima_clean$diastolic[pima_clean$test == "Positive"])
```
We are able to see that the distributions are normally distributed and so we are able to use the t-test (parametric test) to compare the means of the diastolic blood pressures between the two groups (Positive and Negative tests). 

```{r}
t.test(diastolic ~ test, data = pima_clean)  
```

We are able to see from the results of the two sample t-test that the difference in the means of the Diastolic Blood Pressure between the two groups (Positive and Negative) is statistically significant because the p-value is smaller than 0.05. The means in each group are as follows: Negative group (the diastolic blood pressure mean is 70.87) and the Positive group (the diastolic blood pressure mean is 75.32143.) Therefore, we are able to conclude that women who test positive do have higher diastolic blood pressures.  

**I DONT UNDERSTAND THIS ** 
Next, we check whether the predictor variable diastolic blood pressure is significant in the regression model. The regression model that is utilized in this question is the full model. The p-value is 0.90446 

```{r}
summary(full_model)
```


The distinction between the two questions and discuss why the answers are only apparently contradictory 



