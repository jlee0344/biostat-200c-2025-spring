---
title: "Biostat 200C Homework 1"
subtitle: Due Apr 11 @ 11:59PM
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

```{r}
library(gtsummary)
library(GGally)
library(knitr)
library(tidyverse)
library(faraway)
library(gridExtra)
library(splines)
library(mlbench)
```

To submit homework, please submit Rmd and html files to bruinlearn by the deadline.

## Q1. Reivew of linear models (60pts)

The swiss data â€” use Fertility as the response to practice

### Q1.1

An initial data analysis that explores the numerical and graphical characteristics of the data.(5pts)

**Solution ** 
According to online sources, the Swiss Fertility and Socioeconomic Indicators dataset represent the standardized fertility measure and socioeconomic indicators for each of the 47 French-speaking provinces in Switzerland, dated in 1888. 

The swiss data set is a data frame with 47 observations of 6 variables: Fertility (numeric), Agriculture (numeric), Examination (integer), Education (integer), Catholic (numeric), and Infant Mortality (numeric). The variables are represented as follows: 1. Fertility (commmon fertility measure in Ig), 2. Agriculture (percentage of males involved in agriculture as occupation), 3. Examination (percentages of draftees receiving highest mark on army examination), 4. Education (percentage eduation beyond primary school for draftees), 5. Catholic (percent of catholics as opposed to protestants), 6. Infant Mortality (live births who live less than 1 year). 

```{r}
data(swiss)
```

```{r}
swiss <- swiss %>% 
  as_tibble(rownames = "Provinces") %>%
  print(width = Inf)
```

```{r}
str(swiss)
```
The summary statistics (minimum, 1st quartile, median, mean 3rd quartile, and maximum) of the variables in the swiss dataset are as follows: 

```{r}
summary(swiss) 
```

Data Visualization Plots: Univariate 

1. Univariate plot of the Fertility Variable: 
```{r}
ggplot(swiss, aes(x = Fertility)) +
  geom_histogram(aes(y = ..density..), bins = 20, fill = "skyblue", color = "black", alpha = 0.6) +
  geom_density(color = "darkblue", linewidth = 1) +
  labs(
    title = "Histogram of Fertility Rates in Swiss Provinces",
    x = "Fertility Rate",
    y = "Density"
  ) +
  theme_minimal()

unique(swiss$Examination)
```

2. Boxplots for the Predictor Variables: 
```{r}
# Select only predictor variables
predictor_vars <- c("Agriculture", "Examination", "Education", "Catholic", "Infant.Mortality")

# Reshape to long format
swiss_long <- swiss %>%
  pivot_longer(cols = all_of(predictor_vars), names_to = "Variable", values_to = "Value")

# Faceted boxplot
ggplot(swiss_long, aes(x = "", y = Value)) +
  geom_boxplot(fill = "lightgreen") +
  facet_wrap(~ Variable, scales = "free_y") +
  labs(title = "Boxplots of Predictor Variables in the Swiss Dataset", x = "", y = "") +
  theme_minimal()
```
```{r}
# 3. Density plots for all variables including Fertility
swiss_long <- swiss %>%
  pivot_longer(cols = -Provinces, names_to = "Variable", values_to = "Value")

ggplot(swiss_long, aes(x = Value)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  facet_wrap(~ Variable, scales = "free", ncol = 2) +
  labs(title = "Density Plots of Swiss Dataset Variables")
```

Data Visualization: Multivariable Relationships

We will create several scatter plots between 2 variables because all 6 variables are continuous. 

```{r}
ggplot(swiss_long, aes(x = Value, y = Fertility)) +
  geom_point(color = "steelblue", size = 2) +
  geom_smooth(method = "loess", se = TRUE, fill = "gray", color = "darkred", size = 1) +
  facet_wrap(~ Predictor, scales = "free_x", strip.position = "bottom") +
  labs(
    title = "Fertility vs Predictor Variables (Loess Curves + Uncertainty)",
    x = "Predictor Value",
    y = "Fertility"
  ) +
  theme_minimal() +
  theme(
    strip.placement = "outside",              
    strip.background = element_blank(),      
    axis.title.x = element_text(margin = margin(t = 10)),
    axis.text.x = element_text(angle = 0)    
  )
```

Data Visualization: Correlation Plots
```{r}

```


### Q1.2

Variable selection to choose the best model. (10pts)

**Solution ** 

```{r}
blmodi <- lm(Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality, data = swiss)
par(mfrow = c(1,2))
termplot(lmodi, partial.resid = TRUE, terms = 2) 
termplot(blmodi, partial.resid = TRUE, terms = 2) 
```

### Q1.3

An exploration of transformations to improve the fit of the model. (10pts)

**Solution **
```{r}

```


### Q1.4
Diagnostics to check the assumptions of your model. (10pts)

**Solution ** 
We conduct Regression Diagnostics. We recall that the assumptions of the linear model: 
1. Y depends on the covariates in X linearly: E(Y) = XB or E(e) = 0. We use the residual-fitted valu plot, scale location plot, and residual-leverae plto to check for this: 

2. Errors are iid with common variance. We use the QQ plot to check the normality assumption.

```{r}

```


### Q1.5
Some predictions of future observations for interesting values of the predictors.(5pts)

**Solution ** 
```{r}

```


### Q1.6
An interpretation of the meaning of the model by writing a scientific abstract. (<150 words) (10pts)

  + BACKGROUND: brief intro of the study background, what are the existing findings
  
  + OBJECTIVE: state the overall purpose of your research, e.g., what kind of knowledge gap you are trying to fill in
  
  + METHODS: study design (how these data were collected), outcome definitions, statistical procedures used
  
  + RESULTS: summary of major findings to address the question raised in objective
  
  + CONCLUSIONS:


## Q2.(70pts)  

The National Institute of Diabetes and Digestive and Kidney Diseases conducted a study on 768 adult female Pima Indians living near Phoenix. The purpose of the study was to investigate factors related to diabetes. The data may be found in the the dataset `pima`.

```{r}
data(pima)
str(pima)
summary(pima)
```

### Q2.1 

Create a factor version of the test results and use this to produce an interleaved histogram to show how the distribution of insulin differs between those testing positive and negative. Do you notice anything unbelievable about the plot? (5pts)

**Solution **

```{r}
pima$test <- factor(pima$test, levels = c(0,1), labels = c("Negative", "Positive"))
```

Producing an Interleaved Histogram: 

```{r}
ggplot(pima, aes(x = insulin, fill = test)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs( 
    title = "Insulin Levels by Test Result",
    x = "Insulin",
    y = "Count",
    fill = "Test Result"
  ) +
  theme_minimal()
```

Abnormalities of the graph: The histogram displays a large concentration of insulin values at 0, which is highly improbable for human insulin levels. This anomaly likely indicates missing or unrecorded measurements that were incorrectly entered as zero, rather than representing true physiological data. Additionally, the graph reveals the presence of extreme outliers, with some insulin values exceeding 750. Such values are not biologically plausible and may be the result of data entry errors or measurement inaccuracies. 

### Q2.2

Replace the zero values of `insulin` with the missing value code `NA`. Recreate the interleaved histogram plot and comment on the distribution. (5pts)

```{r}
pima$insulin <- ifelse(pima$insulin == 0, NA, pima$insulin)
```

```{r}
ggplot(pima, aes(x = insulin, fill = test)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30, na.rm = TRUE) +
  labs(
    title = "Insulin Levels by Test Result (After removing all NA values)",
    x = "Insulin Level",
    y = "Count",
    fill = "Test Result"
  ) +
  theme_minimal()
```

Creating the interleaved histogram plot: Amongst the Pima Indians who tested negative (pink), the majority of individuals have insulin levels clustered between 0-150. There is a peak at around insulin levels of 100-125. In addition, the distribution of insulin levels is right skewed where there are fewer people with higher insulin levels. There are a couple of outliers of individuals whose insulin levels are above 300. Amongst the Pima Indians who tested positive (blue), the majority of individuals have insulin levels clustered between 100-250. The distribution is more spread out compard to the distribution corresponding to the inuslin levels of the Pima Indians who tested negative. Compared to the negative group, the positive group has a longer right tail, which suggests that some individuals who tested positive have very high insulin levels of above 500. 

### Q2.3

Replace the incredible zeroes in other variables with the missing value code. Fit a model with the result of the diabetes test as the response and all the other variables as predictors. How many observations were used in the model fitting? Why is this less than the number of observations in the data frame. (10pts)
 
**Solution ** 
We observe from the output of summary(pima) that several predictor variables have a minimum value of 0, specifically: glucose, diastolic, triceps, insulin, and bmi. These values are medically implausible and likely represent missing data, so we will convert them to N/A. However, we will not convert the 0 values in the pregnant variable, as it is perfectly reasonable for individuals in the dataset to have had zero pregnancies and is therefore not indicative of missing data. 

```{r}
summary(pima)
variables <- c("glucose", "diastolic", "triceps", "bmi") 
pima[variables] <- lapply(pima[variables], function(x) ifelse(x == 0, NA, x))
```

```{r}
pima_clean <- na.omit(pima)
nrow(pima_clean)

model_first <- glm(test ~ ., data = pima_clean, family = binomial)
model_first
```
The number of observations used in the model fitting is 392. This is fewer than the 768 observations in the original data frame because we removed all rows containing missing values in the predictor variables. The original dataset included rows with invalid zero values in variables such as glucose, diastolic, triceps, insulin, and bmi, which are not physiologically realistic. These zeroes were replaced with NA, and the rows containing them were excluded during model fitting to ensure data quality.

### Q2.4

Refit the model but now without the insulin and triceps predictors. How many observations were used in fitting this model? Devise a test to compare this model with that in the previous question. (10pts)

```{r}
model_second <- glm(test ~ . -insulin -triceps, data = pima_clean, family = binomial)
model_second 
nrow(model.frame(model_second))
```
We refit the model without the insulin and triceps predictors. The number of observations used in fitting this model is 392, the same as in the previous model, since we are using the same cleaned dataset (pima_clean) with all missing values already removed. The only difference is that this model excludes the insulin and triceps variables as predictors.

Test to compare this model to the previous model (that included insulin and triceps): We use the likelihood ratio test to compare the two models. The likelihood ratio test compares the goodness of fit of two models and checks whether removing the two predictors - insulin and triceps significantly worsens the model's fit where the null hypothesis is that the reduced model fits the data just as well as the full model. The p-value is 0.6507 (larger than 0.05) so we fail to reject the null hypothesis. Therefore, we have sufficient evidence to conclude the reduced model (without the 2 predictors insulin and triceps) fits the data just as well as the full model and do not significantly contribute to the model when the other predictors are already included in the model. 

```{r}
anova(model_second, model_first, test = "Chisq")
```

### Q2.5

Use AIC to select a model. You will need to take account of the missing values. Which predictors are selected? How many cases are used in your selected model? (10pts)

**Solution ** 

We perform step-wise selection, adding or dropping predictors to minimize the AIC. We start with the full model that contains all the predictors (pregnant, glucose, diastolic, tricpes, insulin, bmi, diabetes, and age) after removing all the rows that contain NA values. The model selection process of AIC balances the goodness of fit (how well the model explains the data) and the model complexity (penalizes the number of predictors). The lower the AIC, the better the model. Once we start with the full model, we iteratively add or remove predictors (both forward seelctin and backward elimination). 

```{r}
variables <- c("glucose", "diastolic", "triceps", "insulin", "bmi")
pima[variables] <- lapply(pima[variables], function(x) ifelse(x == 0, NA, x))
pima_clean <- na.omit(pima)
full_model <- glm(test ~ ., data = pima_clean, family = binomial)
full_model 

selected_model <- step(full_model, direction = "both")
```

The model with the lowest AIC value comes out to be the one with the following variables: pregnant + glucose + bmi + diabetes + age. Therefore the best model is represented as: 

```{r}
summary(selected_model) 
```


### Q2.6

Create a variable that indicates whether the case contains a missing value. Use this variable as a predictor of the test result. Is missingness associated with the test result? Refit the selected model, but now using as much of the data as reasonable. Explain why it is appropriate to do this. (10pts)

```{r}
pima$misssing 
```

From above regression, we found missingness was not associate with outcome. This means that the distribution of outcome when removing data with missing is still a representative of the original distribution. This justifies the use of "complete case" analysis. 

### Q2.7 

Using the last fitted model of the previous question, what is the difference in the odds of testing positive for diabetes for a woman with a BMI at the first quartile compared with a woman at the third quartile, assuming that all other factors are held constant? Give a confidence interval for this difference.(10pts)


**Solution ** 

```{r}

```

The difference in the odds of testing positive for diabetes for a woman with a BMI at the first quartile compared wiht a woman at the third quartile, assumign hat all other factors are held constant 

The confidence interval for this difference is 

### Q2.8 

Do women who test positive have higher diastolic blood pressures? Is the diastolic blood pressure significant in the regression model? Explain the distinction between the two questions and discuss why the answers are only apparently contradictory. (10pts)
```{r}

```






